"""
V3 ëª¨ë¸: ì›ë³¸ ë°ì´í„° ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
(êµ¬ì¡°ëŠ” V2ì™€ ë™ì¼, ë°ì´í„°ë§Œ ë‹¤ë¦„)
"""

import numpy as np
import pandas as pd
import json
import shutil
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from xgboost import XGBRegressor
import onnx
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType
import onnxruntime as rt


# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path("/Users/sangwon/Project/Sesac_class/bluedonulab-01/match_ML_v3")
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"
BEST_MODEL_DIR = BASE_DIR / "best_model"


def load_data():
    """V3 í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
    df = pd.read_csv(DATA_DIR / "training_data_v3.csv")

    # Feature columns (V2ì™€ ë™ì¼í•œ 13ê°œ)
    feature_cols = [
        'empathy_diff', 'patience_diff', 'activity_diff', 'independence_diff',
        'max_diff', 'avg_diff',
        'empathy_diff_sq', 'patience_diff_sq',
        'empathy_patience_interaction',
        'resident_empathy', 'resident_patience',
        'caregiver_empathy', 'caregiver_patience'
    ]

    X = df[feature_cols].values
    y = df['satisfaction_score'].values

    return train_test_split(X, y, test_size=0.2, random_state=42), feature_cols


def evaluate_model(y_true, y_pred, model_name):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    accuracy_5 = np.mean(np.abs(y_true - y_pred) <= 5) * 100
    accuracy_10 = np.mean(np.abs(y_true - y_pred) <= 10) * 100

    return {
        'model_name': model_name,
        'rmse': round(rmse, 2),
        'mae': round(mae, 2),
        'r2_score': round(r2, 4),
        'accuracy_within_5': round(accuracy_5, 2),
        'accuracy_within_10': round(accuracy_10, 2)
    }


def convert_to_onnx(model, model_name, X_sample, feature_cols):
    """ëª¨ë¸ì„ ONNX í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    onnx_path = MODELS_DIR / f"{model_name}.onnx"

    try:
        if isinstance(model, XGBRegressor):
            # XGBoostëŠ” JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
            json_path = MODELS_DIR / f"{model_name}.json"
            model.save_model(str(json_path))
            print(f"  âœ… XGBoost JSON ì €ì¥: {json_path.name}")
            return True
        else:
            # Sklearn ëª¨ë¸ â†’ ONNX
            initial_type = [('float_input', FloatTensorType([None, X_sample.shape[1]]))]
            onnx_model = convert_sklearn(
                model,
                initial_types=initial_type,
                target_opset=12
            )

            onnx.save_model(onnx_model, str(onnx_path))
            onnx_model_check = onnx.load(str(onnx_path))
            onnx.checker.check_model(onnx_model_check)

            print(f"  âœ… ONNX ë³€í™˜ ì„±ê³µ: {onnx_path.name}")
            return True

    except Exception as e:
        print(f"  âŒ ë³€í™˜ ì‹¤íŒ¨ ({model_name}): {e}")
        return False


def train_all_models():
    """ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
    print("=" * 60)
    print("ğŸ¤– V3 ëª¨ë¸: ì›ë³¸ ë°ì´í„° ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ")
    print("=" * 60)

    # ë°ì´í„° ë¡œë“œ
    (X_train, X_test, y_train, y_test), feature_cols = load_data()
    print(f"\nğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
    print(f"  - í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ")
    print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")
    print(f"  - Feature ê°œìˆ˜: {X_train.shape[1]}ê°œ")

    # ëª¨ë¸ ì •ì˜ (V2ì™€ ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°)
    models = {
        'linear_regression': LinearRegression(),
        'random_forest': RandomForestRegressor(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42
        ),
        'xgboost': XGBRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42
        ),
        'svm': SVR(
            kernel='rbf',
            C=100,
            gamma='scale',
            epsilon=0.1
        ),
        'neural_network': MLPRegressor(
            hidden_layer_sizes=(128, 64, 32),
            max_iter=1000,
            learning_rate_init=0.001,
            random_state=42,
            early_stopping=True
        )
    }

    results = []

    # ê° ëª¨ë¸ í•™ìŠµ
    for model_name, model in models.items():
        print(f"\n{'='*60}")
        print(f"ğŸ”§ {model_name.upper()} í•™ìŠµ ì¤‘...")
        print(f"{'='*60}")

        # í•™ìŠµ
        model.fit(X_train, y_train)

        # ì˜ˆì¸¡
        y_pred = model.predict(X_test)

        # í‰ê°€
        metrics = evaluate_model(y_test, y_pred, model_name)
        results.append(metrics)

        print(f"\nğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"  - RMSE: {metrics['rmse']:.2f}")
        print(f"  - MAE: {metrics['mae']:.2f}")
        print(f"  - RÂ² Score: {metrics['r2_score']:.4f}")
        print(f"  - Â±5ì  ì´ë‚´ ì •í™•ë„: {metrics['accuracy_within_5']:.2f}%")
        print(f"  - Â±10ì  ì´ë‚´ ì •í™•ë„: {metrics['accuracy_within_10']:.2f}%")

        # ONNX ë³€í™˜
        print(f"\nğŸ”„ ë³€í™˜ ì¤‘...")
        convert_to_onnx(model, model_name, X_train, feature_cols)

    return results, feature_cols


def find_best_model(results):
    """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ ì •"""
    best_model = max(results, key=lambda x: x['r2_score'])
    return best_model


def copy_best_model(best_model_name):
    """ìµœê³  ëª¨ë¸ì„ best_model í´ë”ì— ë³µì‚¬"""
    src = MODELS_DIR / f"{best_model_name}.json"
    dst = BEST_MODEL_DIR / "best_model_v3.json"

    if not src.exists():
        src = MODELS_DIR / f"{best_model_name}.onnx"
        dst = BEST_MODEL_DIR / "best_model_v3.onnx"

    if src.exists():
        shutil.copy2(src, dst)
        print(f"\nâœ… ìµœê³  ëª¨ë¸ ë³µì‚¬ ì™„ë£Œ:")
        print(f"  - ì›ë³¸: {src}")
        print(f"  - ë³µì‚¬ë³¸: {dst}")


def save_results(results, best_model, feature_cols):
    """ê²°ê³¼ ì €ì¥"""
    # ì „ì²´ ë¹„êµ ê²°ê³¼
    comparison = {
        'version': 'V3 (ì›ë³¸ ë°ì´í„° ê¸°ë°˜)',
        'models': results,
        'best_model': best_model,
        'feature_columns': feature_cols,
        'timestamp': pd.Timestamp.now().isoformat()
    }

    comparison_path = BASE_DIR / "model_comparison_v3.json"
    with open(comparison_path, 'w', encoding='utf-8') as f:
        json.dump(comparison, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ ë¹„êµ ê²°ê³¼ ì €ì¥: {comparison_path}")

    # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì •ë³´
    best_info = {
        'version': 'V3 (ì›ë³¸ ë°ì´í„° ê¸°ë°˜)',
        'model_name': best_model['model_name'],
        'metrics': best_model,
        'feature_columns': feature_cols,
        'timestamp': pd.Timestamp.now().isoformat()
    }

    best_info_path = BEST_MODEL_DIR / "model_info_v3.json"
    with open(best_info_path, 'w', encoding='utf-8') as f:
        json.dump(best_info, f, indent=2, ensure_ascii=False)

    print(f"ğŸ’¾ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì •ë³´ ì €ì¥: {best_info_path}")


def print_summary(results, best_model):
    """ìµœì¢… ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 60)
    print("ğŸ“Š V3 ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    print("=" * 60)

    # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
    df_results = pd.DataFrame(results)
    df_results = df_results.sort_values('r2_score', ascending=False)

    print("\n" + df_results.to_string(index=False))

    print("\n" + "=" * 60)
    print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model['model_name'].upper()}")
    print("=" * 60)
    print(f"  - RÂ² Score: {best_model['r2_score']:.4f}")
    print(f"  - RMSE: {best_model['rmse']:.2f}")
    print(f"  - Â±10ì  ì´ë‚´ ì •í™•ë„: {best_model['accuracy_within_10']:.2f}%")
    print("=" * 60)


if __name__ == "__main__":
    # ëª¨ë“  ëª¨ë¸ í•™ìŠµ
    results, feature_cols = train_all_models()

    # ìµœê³  ëª¨ë¸ ì„ ì •
    best_model = find_best_model(results)

    # ìµœê³  ëª¨ë¸ ë³µì‚¬
    copy_best_model(best_model['model_name'])

    # ê²°ê³¼ ì €ì¥
    save_results(results, best_model, feature_cols)

    # ìš”ì•½ ì¶œë ¥
    print_summary(results, best_model)

    print("\nâœ… V3 ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“ ONNX/JSON ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {MODELS_DIR}")
    print(f"ğŸ† ë² ìŠ¤íŠ¸ ëª¨ë¸ ìœ„ì¹˜: {BEST_MODEL_DIR}")
