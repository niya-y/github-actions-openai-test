"""
XGBoost ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜ (XGBoost 2.x ë²„ì „ ì‚¬ìš©)
"""

import numpy as np
import pandas as pd
from pathlib import Path
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import onnx
from onnxmltools.convert import convert_xgboost
from onnxmltools.convert.common.data_types import FloatTensorType
import onnxruntime as rt

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path("/Users/sangwon/Project/Sesac_class/bluedonulab-01/match_ML")
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"
BEST_MODEL_DIR = BASE_DIR / "best_model"

print("=" * 60)
print("ğŸ”„ XGBoost â†’ ONNX ë³€í™˜ (XGBoost 2.x)")
print("=" * 60)

# 1. ë°ì´í„° ë¡œë“œ
print("\nğŸ“Š 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ")
df = pd.read_csv(DATA_DIR / "training_data.csv")

feature_cols = [
    'empathy_diff', 'patience_diff', 'activity_diff', 'independence_diff',
    'max_diff', 'avg_diff',
    'empathy_diff_sq', 'patience_diff_sq',
    'empathy_patience_interaction',
    'patient_empathy', 'patient_patience',
    'caregiver_empathy', 'caregiver_patience'
]

X = df[feature_cols].values
y = df['satisfaction_score'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"  - í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ")
print(f"  - Feature ê°œìˆ˜: {len(feature_cols)}ê°œ")

# 2. XGBoost ëª¨ë¸ í•™ìŠµ
print("\nğŸ”§ 2ë‹¨ê³„: XGBoost 2.x ëª¨ë¸ í•™ìŠµ")
model = XGBRegressor(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    tree_method='hist'  # ì•ˆì •ì„±ì„ ìœ„í•´
)

model.fit(X_train, y_train)

# ì„±ëŠ¥ í™•ì¸
y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)
print(f"  âœ… RÂ² Score: {r2:.4f}")

# 3. ONNX ë³€í™˜ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•)
print("\nğŸ”„ 3ë‹¨ê³„: ONNX ë³€í™˜ ì‹œë„")

# ë°©ë²• 1: onnxmltools ì‚¬ìš©
print("\n  ë°©ë²• 1: onnxmltools ì§ì ‘ ë³€í™˜...")
try:
    # Booster ê°ì²´ ì¶”ì¶œ
    booster = model.get_booster()

    # ì´ˆê¸° íƒ€ì… ì •ì˜
    n_features = len(feature_cols)
    initial_type = [('float_input', FloatTensorType([None, n_features]))]

    # ONNX ë³€í™˜
    onnx_model = convert_xgboost(
        booster,
        name='XGBoostRegressor',
        initial_types=initial_type,
        target_opset=12
    )

    # ì €ì¥
    onnx_path = MODELS_DIR / "xgboost.onnx"
    onnx.save_model(onnx_model, str(onnx_path))

    # ê²€ì¦
    onnx.checker.check_model(onnx_model)

    print(f"    âœ… ë³€í™˜ ì„±ê³µ: {onnx_path}")

    # ONNX Runtime í…ŒìŠ¤íŠ¸
    print("\n  ğŸ§ª ONNX ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
    sess = rt.InferenceSession(str(onnx_path))

    # ì…ë ¥/ì¶œë ¥ í™•ì¸
    input_name = sess.get_inputs()[0].name
    output_name = sess.get_outputs()[0].name

    print(f"    - ì…ë ¥ ì´ë¦„: {input_name}")
    print(f"    - ì¶œë ¥ ì´ë¦„: {output_name}")

    # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    X_test_sample = X_test[:5].astype(np.float32)

    # XGBoost ì˜ˆì¸¡
    xgb_pred = model.predict(X_test_sample)

    # ONNX ì˜ˆì¸¡
    onnx_pred = sess.run([output_name], {input_name: X_test_sample})[0]

    # ë¹„êµ
    print(f"\n    ì˜ˆì¸¡ ë¹„êµ:")
    print(f"    - XGBoost: {xgb_pred[:3]}")
    print(f"    - ONNX:    {onnx_pred.flatten()[:3]}")

    # ì°¨ì´ í™•ì¸
    max_diff = np.max(np.abs(xgb_pred - onnx_pred.flatten()))
    print(f"    - ìµœëŒ€ ì°¨ì´: {max_diff:.6f}")

    if max_diff < 0.01:
        print(f"    âœ… ì˜ˆì¸¡ ì¼ì¹˜! (ì˜¤ì°¨ < 0.01)")

        # best_model í´ë”ì— ë³µì‚¬
        best_onnx_path = BEST_MODEL_DIR / "xgboost.onnx"
        onnx.save_model(onnx_model, str(best_onnx_path))
        print(f"\nâœ… ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥: {best_onnx_path}")

        # ëª¨ë¸ ì •ë³´ ì—…ë°ì´íŠ¸
        import json
        model_info = {
            'model_name': 'xgboost',
            'format': 'ONNX',
            'r2_score': float(r2),
            'xgboost_version': '2.1.4',
            'onnx_opset': 12,
            'feature_names': feature_cols,
            'n_features': len(feature_cols),
            'input_name': input_name,
            'output_name': output_name,
            'note': 'Converted successfully with XGBoost 2.x + onnxmltools'
        }

        info_path = BEST_MODEL_DIR / "xgboost_onnx_info.json"
        with open(info_path, 'w') as f:
            json.dump(model_info, f, indent=2)
        print(f"âœ… ëª¨ë¸ ì •ë³´ ì €ì¥: {info_path}")

        print("\n" + "=" * 60)
        print("ğŸ‰ XGBoost ONNX ë³€í™˜ ì„±ê³µ!")
        print("=" * 60)
        print(f"\nğŸ“ ONNX íŒŒì¼ ìœ„ì¹˜:")
        print(f"  - {onnx_path}")
        print(f"  - {best_onnx_path}")

    else:
        print(f"    âš ï¸  ì˜ˆì¸¡ ì°¨ì´ê°€ í¼ (>{0.01})")

except Exception as e:
    print(f"    âŒ ë°©ë²• 1 ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()

    # ë°©ë²• 2: sklearn wrapper ì‚¬ìš©
    print("\n  ë°©ë²• 2: sklearn wrapper ì‹œë„...")
    try:
        from skl2onnx import convert_sklearn
        from skl2onnx.common.data_types import FloatTensorType

        initial_type = [('float_input', FloatTensorType([None, len(feature_cols)]))]

        onnx_model = convert_sklearn(
            model,
            initial_types=initial_type,
            target_opset=12
        )

        onnx_path = MODELS_DIR / "xgboost.onnx"
        onnx.save_model(onnx_model, str(onnx_path))

        print(f"    âœ… ë°©ë²• 2 ì„±ê³µ: {onnx_path}")

    except Exception as e2:
        print(f"    âŒ ë°©ë²• 2ë„ ì‹¤íŒ¨: {e2}")
        print("\nâš ï¸  ONNX ë³€í™˜ ì‹¤íŒ¨ - JSON/PKL í˜•ì‹ ì‚¬ìš© ê¶Œì¥")
