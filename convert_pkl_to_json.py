"""
PKL ëª¨ë¸ì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
ìƒˆ ì•Œê³ ë¦¬ì¦˜ (neulbomcare-matching 2) â†’ í˜„ì¬ í”„ë¡œì íŠ¸ í†µí•©
"""

import joblib
from xgboost import XGBRegressor
from pathlib import Path
import json
import shutil

# ê²½ë¡œ ì„¤ì •
SOURCE_DIR = Path("/Users/sangwon/Project/Sesac_class/neulbom-merge/neulbomcare-matching 2")
TARGET_DIR = Path("/Users/sangwon/Project/Sesac_class/neulbom-merge/neulbomcare-test03/backend/models")

# ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
TARGET_DIR.mkdir(parents=True, exist_ok=True)

print("=" * 60)
print("ğŸ”„ PKL ëª¨ë¸ â†’ JSON ë³€í™˜")
print("=" * 60)

# 1. PKL ëª¨ë¸ ë¡œë“œ
print("\n1ï¸âƒ£ PKL ëª¨ë¸ ë¡œë“œ ì¤‘...")
pkl_path = SOURCE_DIR / "models" / "xgboost_regressor.pkl"

if not pkl_path.exists():
    print(f"âŒ PKL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pkl_path}")
    exit(1)

model = joblib.load(pkl_path)
print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {pkl_path}")
print(f"   - ëª¨ë¸ íƒ€ì…: {type(model).__name__}")

# 2. JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
print("\n2ï¸âƒ£ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
json_path = TARGET_DIR / "xgboost_v2.json"
model.save_model(str(json_path))
print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {json_path}")

# íŒŒì¼ í¬ê¸° í™•ì¸
file_size = json_path.stat().st_size / 1024  # KB
print(f"   - íŒŒì¼ í¬ê¸°: {file_size:.1f} KB")

# 3. íŠ¹ì„± ì»¬ëŸ¼ ì •ë³´ ë³µì‚¬
print("\n3ï¸âƒ£ íŠ¹ì„± ì»¬ëŸ¼ ì •ë³´ ë³µì‚¬ ì¤‘...")
feature_source = SOURCE_DIR / "models" / "feature_columns.json"
feature_target = TARGET_DIR / "feature_columns_v2.json"

if feature_source.exists():
    shutil.copy2(feature_source, feature_target)
    print(f"âœ… íŠ¹ì„± ì •ë³´ ë³µì‚¬ ì™„ë£Œ: {feature_target}")
    
    # íŠ¹ì„± ì»¬ëŸ¼ í™•ì¸
    with open(feature_target, 'r') as f:
        features = json.load(f)
    print(f"   - íŠ¹ì„± ê°œìˆ˜: {len(features)}ê°œ")
    print(f"   - íŠ¹ì„± ëª©ë¡:")
    for i, feat in enumerate(features, 1):
        print(f"     {i}. {feat}")
else:
    print(f"âš ï¸  íŠ¹ì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {feature_source}")

# 4. í•™ìŠµ ê²°ê³¼ ì •ë³´ ë³µì‚¬
print("\n4ï¸âƒ£ í•™ìŠµ ê²°ê³¼ ì •ë³´ ë³µì‚¬ ì¤‘...")
results_source = SOURCE_DIR / "models" / "training_results.json"
results_target = TARGET_DIR / "training_results_v2.json"

if results_source.exists():
    shutil.copy2(results_source, results_target)
    print(f"âœ… í•™ìŠµ ê²°ê³¼ ë³µì‚¬ ì™„ë£Œ: {results_target}")
    
    # ì„±ëŠ¥ ì§€í‘œ í™•ì¸
    with open(results_target, 'r') as f:
        results = json.load(f)
    
    if 'regression' in results and 'xgboost_regressor' in results['regression']:
        metrics = results['regression']['xgboost_regressor']
        print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"   - RÂ² Score: {metrics.get('R2', 'N/A'):.4f}")
        print(f"   - RMSE: {metrics.get('RMSE', 'N/A'):.2f}")
        print(f"   - MAE: {metrics.get('MAE', 'N/A'):.2f}")
else:
    print(f"âš ï¸  í•™ìŠµ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_source}")

# 5. ê¸°ì¡´ ëª¨ë¸ ë°±ì—…
print("\n5ï¸âƒ£ ê¸°ì¡´ ëª¨ë¸ ë°±ì—… ì¤‘...")
old_model_path = TARGET_DIR.parent.parent / "Match_Algorithm_System" / "match_ML_v3" / "models" / "xgboost.json"

if old_model_path.exists():
    backup_path = TARGET_DIR / "xgboost_v1_backup.json"
    shutil.copy2(old_model_path, backup_path)
    print(f"âœ… ê¸°ì¡´ ëª¨ë¸ ë°±ì—… ì™„ë£Œ: {backup_path}")
else:
    print(f"âš ï¸  ê¸°ì¡´ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {old_model_path}")

# 6. ìµœì¢… í™•ì¸
print("\n" + "=" * 60)
print("âœ… ë³€í™˜ ì™„ë£Œ!")
print("=" * 60)
print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
print(f"   1. {json_path}")
print(f"   2. {feature_target}")
print(f"   3. {results_target}")
print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
print(f"   1. feature_engineering.py ë³µì‚¬")
print(f"   2. xgboost_matching_service.py ì—…ë°ì´íŠ¸")
print(f"   3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
print()
