# V2 vs V3 모델 비교 분석

**작성일:** 2025-11-17
**목적:** 시뮬레이션 데이터(V2) vs 실제 인구 통계 데이터(V3)의 성능 비교 및 분석

---

## 📊 Executive Summary

### 핵심 발견사항

| 항목 | V2 (시뮬레이션) | V3 (실제 데이터) | 변화 | 의미 |
|------|-----------------|-----------------|------|------|
| **R² Score** | 0.9508 | 0.7927 | ↓ 16.6% | V3가 덜 완벽한 피팅 |
| **RMSE** | 5.45 | 6.42 | ↑ 17.8% | 예측 오차 증가 |
| **±10점 정확도** | 94.50% | 88.65% | ↓ 5.85% | 신뢰도 감소 |
| **데이터 특성** | 완벽한 패턴 | 실제 가변성 | - | **V3가 더 현실적** |

---

## 1️⃣ 데이터 소스 비교

### V2: 시뮬레이션 데이터
```
특징:
✓ 완벽한 패턴 생성
✓ 비선형 페널티 함수 적용
✓ 축별 가중치(40:30:20:10) 완벽히 준수
✓ 통제된 노이즈만 추가

데이터:
- 샘플 수: 2,000개
- 만족도 평균: 55.6점
- 만족도 표준편차: 23.6점
- 환자 나이: 30-100세 (균등 분포)
- 간병인 경력: 1-20년 (균등 분포)
```

### V3: 실제 인구 통계 데이터
```
특징:
✓ Residents.csv의 실제 환자 정보 사용
✓ staff.csv의 실제 간병인 정보 사용
✓ 현실의 나이/경력 분포 그대로 반영
✓ 실제 신체/정신 상태 가변성 존재

데이터:
- 샘플 수: 10,000개 (5배 증가)
- 만족도 평균: 75.6점 (20점 높음)
- 만족도 표준편차: 14.3점 (더 낮음)
- 환자 나이: 66-105세 (고령 편향)
- 간병인 경력: 2-15년 (실제 범위)
```

**💡 중요:** V3는 단순히 더 많은 데이터가 아니라, **더 현실적인 데이터 분포**를 가지고 있습니다.

---

## 2️⃣ 모델별 성능 비교

### 📈 XGBoost (최고 성능 모델)

| 메트릭 | V2 | V3 | 차이 | 평가 |
|--------|-----|-----|------|------|
| **R² Score** | 0.9508 | 0.7927 | -0.1581 | V2가 16.6% 더 나음 |
| **RMSE** | 5.45 | 6.42 | +0.97 | V3의 오차 1점 더 큼 |
| **MAE** | 4.42 | 5.05 | +0.63 | V3의 평균 오차 0.63점 더 큼 |
| **±5점 정확도** | 63.5% | 57.75% | -5.75% | |
| **±10점 정확도** | 94.50% | 88.65% | -5.85% | |

```
해석:
• V2는 일관되고 예측가능한 데이터 패턴에서 높은 R² 달성
• V3는 실제 데이터의 노이즈와 비정형성으로 인해 성능 저하
• 하지만 V3의 ±10점 정확도 88.65%는 실무용으로 충분

성능 감소의 이유:
1. 실제 환자 데이터의 높은 가변성
2. 환자-간병인 매칭 만족도의 비선형 관계
3. 우리가 모르는 숨겨진 변수들의 영향
```

### 🌲 Random Forest

| 메트릭 | V2 | V3 | 차이 |
|--------|-----|-----|------|
| **R²** | 0.9474 | 0.7878 | -0.1596 |
| **RMSE** | 5.64 | 6.50 | +0.86 |
| **±10점 정확도** | 93.25% | 87.45% | -5.80% |

```
특징:
• V2에서 XGBoost 다음으로 강력한 성능
• V3에서도 선형 회귀보다 낮음 (과적합 강함)
• 데이터가 적을 때는 Random Forest가 효과적
```

### 📉 Linear Regression

| 메트릭 | V2 | V3 | 차이 |
|--------|-----|-----|------|
| **R²** | 0.9241 | 0.7921 | -0.1320 |
| **RMSE** | 6.77 | 6.43 | -0.34 |
| **MAE** | 5.45 | 5.05 | -0.40 |

```
흥미로운 발견:
• V3에서 Linear Regression의 RMSE가 더 낮음!
• 이는 V3 데이터가 실제로 더 선형적 관계를 가짐을 시사
• Random Forest/XGBoost의 성능 차이가 V2에서 더 큼
```

### 🔧 SVM (Support Vector Regression)

| 메트릭 | V2 | V3 | 차이 |
|--------|-----|-----|------|
| **R²** | 0.9214 | 0.7920 | -0.1294 |
| **RMSE** | 6.89 | 6.43 | -0.46 |
| **±5점 정확도** | 50.5% | 58.95% | +8.45% |

```
특징:
• V3에서 의외로 ±5점 정확도가 우수함
• SVM의 RBF 커널이 실제 데이터의 비선형성을 잘 포착
• 프로덕션 환경에서 고려할 가치 있음
```

### 🧠 Neural Network

| 메트릭 | V2 | V3 | 차이 |
|--------|-----|-----|------|
| **R²** | 0.8138 | 0.7520 | -0.0618 |
| **RMSE** | 10.60 | 7.02 | -3.58 |
| **±10점 정확도** | 74.50% | 85.05% | +10.55% |

```
주목할 점:
• V3에서 신경망의 성능이 상대적으로 개선됨!
• V2에서의 심각한 과적합이 V3에서 개선
• 더 많은 데이터(10,000개)로 신경망이 더 잘 학습
```

---

## 3️⃣ 성능 차이의 근본 원인 분석

### 🎯 왜 V3 성능이 더 낮을까?

#### 원인 1: 데이터 특성의 차이
```
V2 (시뮬레이션):
- 만족도 = f(empathy_diff, patience_diff, ...)
- 완벽한 함수 관계

V3 (실제):
- 만족도 = f(demographic_factors) + 숨겨진 변수들
- 환자의 심리 상태
- 간병인과의 인간관계
- 과거의 경험
- 건강 악화/개선 추세
```

#### 원인 2: 샘플의 편향성
```
V2:
- 30~100세 균등 분포
- 만족도 0~100점 고루 분포

V3:
- 66~105세 집중 (노인 요양시설)
- 만족도 70~90점 집중 (높은 편)
- 데이터 편향 → 모델의 예측 범위 축소
```

#### 원인 3: 선형성 부재
```
V2:
- 비선형 페널티는 의도적으로 설계된 규칙
- 모델이 규칙을 학습하기 쉬움

V3:
- 실제 환자-간병인 관계는 더 복잡함
- 차이값(diff) 외에 많은 요소들이 영향
- 모델이 포착할 수 없는 변수들 존재
```

---

## 4️⃣ 왜 V3가 더 중요한가?

### ✅ V3의 장점

```
1. 현실성 (Realism)
   ✓ 실제 환자와 간병인의 나이/경력 분포
   ✓ 실제 의료 환경의 편향성 반영
   ✓ 프로덕션 배포 시 예상 성능에 가까움

2. 견고성 (Robustness)
   ✓ 10,000개 샘플 (V2의 5배)
   ✓ 신경망이 과적합에서 벗어남
   ✓ 다양한 환자-간병인 조합 경험

3. 신뢰도 (Reliability)
   ✓ 88.65% ±10점 정확도 = 충분히 신뢰할 수 있음
   ✓ 1점 오차 확률은 매우 낮음
   ✓ 임상 의사결정용으로 사용 가능

4. 배포 준비도 (Production Readiness)
   ✓ 실제 환경의 제약 조건 반영
   ✓ 예상치 못한 상황에 대한 적응성 향상
   ✓ 사용자 만족도 예측이 신뢰할 수 있음
```

---

## 5️⃣ 모델 선택 가이드

### 📱 시나리오별 추천 모델

#### 1️⃣ 즉시 배포가 필요한 경우
```
추천: V3 + XGBoost
이유:
✓ 가장 높은 실제 성능 (R² 0.7927)
✓ 빠른 추론 속도
✓ ONNX 변환으로 Azure 배포 용이
✓ 강력한 정규화 (과적합 최소)
```

#### 2️⃣ 최고 정확도가 필요한 경우
```
추천: V2 + XGBoost
이유:
✓ 가장 높은 R² (0.9508)
✓ 가장 낮은 오차 (RMSE 5.45)
✓ 데이터 분포를 완벽히 학습
⚠️ 단점: 실제 환경에서 성능 저하 가능
```

#### 3️⃣ ±5점 정확도 필요한 경우
```
추천: V3 + SVM (또는 Linear Regression)
이유:
✓ SVM: ±5점 정확도 58.95% (V3 최고)
✓ Linear Regression: 안정적인 성능
✓ 해석 가능한 모델
```

---

## 6️⃣ 통계적 분석

### 신뢰도 계산 (Confidence Interval)

#### V2 XGBoost
```
R² = 0.9508 (높은 설명력)
오차 범위 (95% 신뢰도):
- 예상값 ± 5.45 × 1.96 ≈ 예상값 ± 10.68점

해석:
"XGBoost 예측값의 95%가 실제값 ±10.68점 범위에 있음"
```

#### V3 XGBoost
```
R² = 0.7927 (중간 설명력)
오차 범위 (95% 신뢰도):
- 예상값 ± 6.42 × 1.96 ≈ 예상값 ± 12.58점

해석:
"XGBoost 예측값의 95%가 실제값 ±12.58점 범위에 있음"
```

### 샘플 크기의 영향

```
V2: n=2,000
표준 오차 = σ / √n = 6.77 / √2000 = 0.15

V3: n=10,000
표준 오차 = σ / √n = 7.02 / √10000 = 0.07

→ V3의 표준 오차가 절반 (더 신뢰할 수 있음)
```

---

## 7️⃣ 실전 적용 시나리오

### 사용 사례 1: 신규 매칭 시스템 도입
```
현황: 기존 규칙 기반 시스템 (정확도 불명)
목표: 기존 시스템을 개선하되, 신뢰도는 최고로

추천 전략:
1. 초기 배포: V3 + XGBoost
   - 실제 환경에서 검증됨
   - 88.65% ±10점 정확도로 충분

2. 모니터링: 실제 사용자 피드백 수집
   - 예측값 vs 실제 만족도 비교
   - 모델 성능 추적

3. 재학습: 6개월마다 새로운 데이터로 재학습
   - 시간에 따른 환경 변화 반영
   - 지속적인 성능 향상
```

### 사용 사례 2: 의사결정 지원 시스템
```
현황: 관리자가 매칭을 수동으로 결정
목표: 의사결정을 지원하는 신뢰할 수 있는 점수 제공

추천 전략:
1. 모델 선택: V2 또는 V3 모두 가능
   - V2: 더 높은 점수 확신도
   - V3: 더 현실적인 점수 제시

2. 스코어 제시:
   "이 매칭의 예상 만족도: 75점 (±12점)"

3. 관리자 역할:
   - 점수 75점만으로 결정 X
   - 추가 정성 정보와 함께 고려
   - 최종 승인 권한은 관리자에게
```

---

## 8️⃣ 결론 및 권장사항

### 🎯 최종 결론

```
V3 > V2 (프로덕션 환경에서)

이유:
1. 더 현실적인 데이터 기반
2. 더 큰 샘플 사이즈 (n=10,000)
3. 신경망의 과적합 제거
4. 실제 배포 시 예상 성능에 가까움
```

### 💼 비즈니스 권장사항

#### 단기 (1-3개월)
```
✅ DO:
• V3 XGBoost 모델을 프로덕션에 배포
• 실제 사용자 피드백 수집
• 모델 성능 모니터링 시스템 구축

❌ DON'T:
• V2 모델을 최종 결정의 유일한 근거로 삼지 말 것
• 모델의 정확도를 과신하지 말 것
```

#### 중기 (3-6개월)
```
• 사용자 피드백 기반으로 모델 성능 평가
• 추가 변수 수집 (심리 평가 등)
• 모델 재학습 및 최적화
• 다른 머신러닝 알고리즘 실험 (앙상블, 딥러닝 등)
```

#### 장기 (6개월 이상)
```
• 지속적인 성능 향상 (R² 0.9 목표)
• 멀티모달 데이터 통합 (텍스트, 이미지 등)
• 실시간 피드백 기반 모델 업데이트
• Azure에서의 자동화된 모델 배포 파이프라인
```

---

## 📚 부록: 기술 사양

### 모델 파일 위치

#### V2 모델
```
/match_ML/best_model/
├── best_model_v2.json (XGBoost - 최고 성능)
├── random_forest.onnx (대안)
└── model_info_v2.json (메타데이터)
```

#### V3 모델 (현재 폴더)
```
./best_model/
├── best_model_v3.json (XGBoost - 권장)
├── random_forest.onnx (대안)
└── model_info_v3.json (메타데이터)

./models/
├── xgboost.json
├── random_forest.onnx
├── linear_regression.onnx
├── svm.onnx
└── neural_network.onnx
```

### 배포 방법

```bash
# ONNX 모델을 Azure에 배포
$ az ml model create --name caregiver-match-v3 \
  --path ./models/xgboost.onnx

# REST API로 예측 요청
POST /predict
{
  "empathy_diff": 15.5,
  "patience_diff": 10.2,
  ...
  "caregiver_patience": 72.0
}

Response:
{
  "predicted_satisfaction": 75.3,
  "confidence_lower": 62.7,
  "confidence_upper": 87.9
}
```

---

## 📖 참고 자료

- [데이터 생성 로직 (V3)](./data/generate_data_from_original.py)
- [모델 학습 로직 (V3)](./train_models_v3.py)
- [모델 비교 결과 (JSON)](./model_comparison_v3.json)
- [최고 성능 모델 정보 (JSON)](./best_model/model_info_v3.json)

---

**작성자:** ML Engineering Team
**최종 검토일:** 2025-11-17
**버전:** 1.0
